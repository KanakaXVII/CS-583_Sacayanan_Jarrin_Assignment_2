{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Assignment: Build a CNN for image recognition.\n",
    "\n",
    "### Name: Jarrin Sacayanan\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. You will do the following:\n",
    "\n",
    "1. Read, complete, and run the code.\n",
    "\n",
    "2. **Make substantial improvements** to maximize the accuracy.\n",
    "    \n",
    "3. Convert the .IPYNB file to .HTML file.\n",
    "\n",
    "    * The HTML file must contain the code and the output after execution.\n",
    "    \n",
    "    * Missing **the output after execution** will not be graded.\n",
    "\n",
    "\n",
    "4. Upload the .HTML file to your Google Drive, Dropbox, or Github repo. (If you submit the file to Google Drive or Dropbox, you must make the file \"open-access\". The delay caused by \"deny of access\" may result in late penalty.)\n",
    "\n",
    "4. On Canvas, submit the Google Drive/Dropbox/Github link to the HTML file.\n",
    "\n",
    "\n",
    "## Requirements:\n",
    "\n",
    "1. You can use whatever CNN architecture, including VGG, Inception, and ResNet. However, you must build the networks layer by layer. You must NOT import the archetectures from ```keras.applications```.\n",
    "\n",
    "2. Make sure ```BatchNormalization``` is between a ```Conv```/```Dense``` layer and an ```activation``` layer.\n",
    "\n",
    "3. If you want to regularize a ```Conv```/```Dense``` layer, you should place a ```Dropout``` layer **before** the ```Conv```/```Dense``` layer.\n",
    "\n",
    "4. An accuracy above 70% is considered reasonable. An accuracy above 80% is considered good. Without data augmentation, achieving 80% accuracy is difficult.\n",
    "\n",
    "\n",
    "## Google Colab\n",
    "\n",
    "- If you do not have GPU, the training of a CNN can be slow. Google Colab is a good option.\n",
    "\n",
    "- Keep in mind that you must download it as an IPYNB file and then use IPython Notebook to convert it to HTML.\n",
    "\n",
    "- Also keep in mind that the IPYNB and HTML files must contain the outputs. (Otherwise, the instructor will not be able to know the correctness and performance.) Do the followings to keep the outputs.\n",
    "\n",
    "- In Colab, go to ```Runtime``` --> ```Change runtime type``` --> Do NOT check ```Omit code cell output when saving this notebook```. In this way, the downloaded IPYNB file contains the outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [OPTIONAL] Install packages\n",
    "%pip install keras tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [OPTIONAL] Silence warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of x_train: (50000, 32, 32, 3)\n",
      "shape of y_train: (50000, 1)\n",
      "shape of x_test: (10000, 32, 32, 3)\n",
      "shape of y_test: (10000, 1)\n",
      "number of classes: 10\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "import numpy\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "print('shape of x_train: ' + str(x_train.shape))\n",
    "print('shape of y_train: ' + str(y_train.shape))\n",
    "print('shape of x_test: ' + str(x_test.shape))\n",
    "print('shape of y_test: ' + str(y_test.shape))\n",
    "print('number of classes: ' + str(numpy.max(y_train) - numpy.min(y_train) + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. One-hot encode the labels\n",
    "\n",
    "In the input, a label is a scalar in $\\{0, 1, \\cdots , 9\\}$. One-hot encode transform such a scalar to a $10$-dim vector. E.g., a scalar ```y_train[j]=3``` is transformed to the vector ```y_train_vec[j]=[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]```.\n",
    "\n",
    "1. Define a function ```to_one_hot``` that transforms an $n\\times 1$ array to a $n\\times 10$ matrix.\n",
    "\n",
    "2. Apply the function to ```y_train``` and ```y_test```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of y_train_vec: (50000, 10)\n",
      "Shape of y_test_vec: (10000, 10)\n",
      "[6]\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "def to_one_hot(y, num_class=10):\n",
    "    ### START Student Code\n",
    "\n",
    "    # Create an empty matrix\n",
    "    y_hot = numpy.zeros((y.size, num_class))\n",
    "    \n",
    "    # Assign 1 to values in y\n",
    "    for ind, y_i in enumerate(y):\n",
    "        y_hot[ind][y_i] = 1\n",
    "    \n",
    "    return y_hot\n",
    "    ### END Student Code\n",
    "\n",
    "y_train_vec = to_one_hot(y_train)\n",
    "y_test_vec = to_one_hot(y_test)\n",
    "\n",
    "print('Shape of y_train_vec: ' + str(y_train_vec.shape))\n",
    "print('Shape of y_test_vec: ' + str(y_test_vec.shape))\n",
    "\n",
    "print(y_train[0])\n",
    "print(y_train_vec[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remark: the outputs should be\n",
    "* Shape of y_train_vec: (50000, 10)\n",
    "* Shape of y_test_vec: (10000, 10)\n",
    "* [6]\n",
    "* [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Randomly partition the training set to training and validation sets\n",
    "\n",
    "Randomly partition the 50K training samples to 2 sets:\n",
    "* a training set containing 40K samples\n",
    "* a validation set containing 10K samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_tr: (40000, 32, 32, 3)\n",
      "Shape of y_tr: (40000, 10)\n",
      "Shape of x_val: (10000, 32, 32, 3)\n",
      "Shape of y_val: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "rand_indices = numpy.random.permutation(50000)\n",
    "train_indices = rand_indices[0:40000]\n",
    "valid_indices = rand_indices[40000:50000]\n",
    "\n",
    "x_val = x_train[valid_indices, :]\n",
    "y_val = y_train_vec[valid_indices, :]\n",
    "\n",
    "x_tr = x_train[train_indices, :]\n",
    "y_tr = y_train_vec[train_indices, :]\n",
    "\n",
    "print('Shape of x_tr: ' + str(x_tr.shape))\n",
    "print('Shape of y_tr: ' + str(y_tr.shape))\n",
    "print('Shape of x_val: ' + str(x_val.shape))\n",
    "print('Shape of y_val: ' + str(y_val.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build a CNN and tune its hyper-parameters\n",
    "\n",
    "1. Build a convolutional neural network model\n",
    "2. Use the validation data to tune the hyper-parameters (e.g., network structure, and optimization algorithm)\n",
    "    * Do NOT use test data for hyper-parameter tuning!!!\n",
    "3. Try to achieve a validation accuracy as high as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remark: \n",
    "\n",
    "The following CNN is just an example. You are supposed to make **substantial improvements** such as:\n",
    "* Add more layers.\n",
    "* Use regularizations, e.g., dropout.\n",
    "* Use batch normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 16, 16, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 8, 8, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4096)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               524416    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 545,098\n",
      "Trainable params: 545,098\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Example CNN Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My Implementation\n",
    "After running the provided sample model, it achieves the following scores:\n",
    "- **Training**:   0.4966\n",
    "- **Validation**: 0.4777\n",
    "\n",
    "These scores will be the baseline to determine the efficacy of my model adjustments.\n",
    "\n",
    "---\n",
    "## Attempted Optimizations\n",
    "Provided below is a log of all of the different changes I made to the model in efforts to improve the performance. The following cell only represents the final submitted model as I did not want to flood this notebook by creating many different cells for trying different approaches.\n",
    "1. Added two `BatchNormalization()` layers (after the `Conv2D()` layers)\n",
    "    - **Training**: 0.6325\n",
    "    - **Validation**: 0.5866\n",
    "2. Added two `Dropout(rate=0.2)`layers (after the `Conv2D()` layers)\n",
    "    - **Training**: 0.4124 \n",
    "    - **Validation**: 0.4267\n",
    "3. Added two `BatchNormalization()` layers (after the `Conv2D()` layers) and one `Dropout(rate=.1)` layer before the final `Dense()` layer\n",
    "    - **Training**: 0.5999 \n",
    "    - **Validation**: 0.5760\n",
    "4. Added two `BatchNormalization()` layers (after the `Conv2D()` layers), one `Dropout(rate=.2)` layer before the final `Dense()` layer, and increased the batch size from 32 to 64\n",
    "    - **Training**: 0.5370 \n",
    "    - **Validation**: 0.5448\n",
    "5. Added three `BatchNormalization()` layers (after the `Conv2D()` layers), one `MaxPooling2D()`layer, and one `Conv2D(128, (3, 3))` layer\n",
    "    - **Training**: 0.5637 \n",
    "    - **Validation**: 0.5715\n",
    "6. Added two additional rounds of `Conv2D()`, `BatchNormalization()`, and `MaxPooling2D()` layers. Also adjusted learning rate from 1e-5 to 0.001 and batch size from 32 to 64.\n",
    "    - **Training**: 0.8803 \n",
    "    - **Validation**: 0.7484\n",
    "    \n",
    "**Update**: At this point, I have achieved a high training score with a decent validation score, so I feel as though I am on the right track to achieving a solid model. For the next iteration, I will run the same model with a learning rate of 0.0001 instead of 0.001. I will keep the batch size at 64.\n",
    "\n",
    "7. Same as 6, but with a learning rate of 0.0001 instead of 0.001\n",
    "    - **Training**: 0.8462 \n",
    "    - **Validation**: 0.6855\n",
    "    \n",
    "**Update**: This resulted in an even worse training and validation score. I will try the learning rate of 0.001 once again, but I will make more adjustments to the model layers themselves.\n",
    "\n",
    "8. Same as 6, but with two `Dropout()` layers instead of one and an increased dropout rate.\n",
    "    - **Training**: 0.7114 \n",
    "    - **Validation**: 0.6959\n",
    "9. Using a `Dropout()` layer after each `MaxPooling2D()` layer and reducing the dropout rate\n",
    "    - **Training**: 0.7483 \n",
    "    - **Validation**: 0.7266\n",
    "10. Adjusting the filter sizes in all `Conv2D()` layers to try and extract different information\n",
    "    - **Training**: 0.7988 \n",
    "    - **Validation**: 0.6924\n",
    "\n",
    "**Update**: The model is not improving and the validation scores are now sporadically jumping up and down. I will try to use some non-square filters in the `Conv2D()` layers to see if the model can extract some different features and increase the accuracy. I will use the original two `Conv2D()` layers, but I will add two more that use the filter dimensions `(3, 7)` and `(7, 3)` respectively. I will also go back to using a single `Dropout(rate=.5)` layer right before the final `Dense()` layer.\n",
    "\n",
    "11. Trying non-square filter sizes for two additional `Conv2D()` layers and using a single `Dropout()` layer\n",
    "    - **Training**: 0.8864 \n",
    "    - **Validation**: 0.7460\n",
    "\n",
    "**Update**: At this point, I have not moved on to the testing phase. I will try to use the test set now to see what kind of test accuracy I can come up with.\n",
    "\n",
    "**Testing with Model 11**: I fit the model using the entire training set and achieved the following accuracy scores:\n",
    "- **Training**: 0.9496\n",
    "- **Testing**: ~0.7202 \n",
    "\n",
    "This is not ideal, so I will try a few more optimizations to see if I can increase the score. Based on my observations from the training, validation, and testing scores of model 11, it looks like my model is overfitting to the training data. I will try to combat this by adding additional `Dropout()` layers.\n",
    "\n",
    "12. Using model **11**, but adding additional `Dropout()` layers to reduce overfitting.\n",
    "    - **Training**: 0.5903 \n",
    "    - **Validation**: 0.5734\n",
    "\n",
    "**Update**: Adding more dropout layers ***did not*** fix my overfitting problem. I realized I may be performing dropout at the incorrect step in the layer order, so I shifted them to be performed directly after the `Conv2D()` layers. I also reduce the dropout rate to 0.3.\n",
    "\n",
    "13. Replicating model **12**, but moving the `Dropout()` layers to be directly after the `Conv2D()` layers. Also reduced the dropout rate from 0.5 to 0.3.\n",
    "    - **Training**: 0.7878\n",
    "    - **Validation**: 0.6687\n",
    "\n",
    "**Update**: My validation accuracy is persistently low, so I am going to try a different regularizer (`l2`). \n",
    "\n",
    "14. Using Model 11 but including `L2` regularization on the `Conv2D()` layers\n",
    "    - **Training**: 0.7323 \n",
    "    - **Validation**: 0.5900\n",
    "\n",
    "**Update**: This didn't work...I'm going to try to add another `Conv2D()` stack with another filter size. I'm also going to remove the dropout layer and rely solely on L2 for regularization.\n",
    "\n",
    "15. Using model 11 but adding another convolutional stack and removing the `Dropout()` layer\n",
    "    - **Training**: 0.7449 \n",
    "    - **Validation**: 0.6723\n",
    "\n",
    "**Update**: I'm not sure which improvements need to be made to increase the validation accuracy, so I am re-creating model **11**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_57 (Conv2D)          (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " batch_normalization_50 (Bat  (None, 32, 32, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_56 (MaxPoolin  (None, 16, 16, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_58 (Conv2D)          (None, 16, 16, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_51 (Bat  (None, 16, 16, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_57 (MaxPoolin  (None, 8, 8, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_59 (Conv2D)          (None, 8, 8, 128)         172160    \n",
      "                                                                 \n",
      " batch_normalization_52 (Bat  (None, 8, 8, 128)        512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_58 (MaxPoolin  (None, 4, 4, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_60 (Conv2D)          (None, 4, 4, 128)         344192    \n",
      "                                                                 \n",
      " batch_normalization_53 (Bat  (None, 4, 4, 128)        512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_59 (MaxPoolin  (None, 2, 2, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_17 (Flatten)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 128)               65664     \n",
      "                                                                 \n",
      " dropout_29 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 604,106\n",
      "Trainable params: 603,402\n",
      "Non-trainable params: 704\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "from keras.models import Sequential\n",
    "\n",
    "# Initialize the sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Add first convolutional stack\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# Add second convolutional stack\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# Add third convolutional stack\n",
    "model.add(Conv2D(128, (3, 7), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# Add fourth convolutional stack\n",
    "model.add(Conv2D(128, (7, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# Flatten data\n",
    "model.add(Flatten())\n",
    "\n",
    "# Make final predicitons\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "learning_rate = .001 # to be tuned!\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=learning_rate),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "625/625 [==============================] - 41s 63ms/step - loss: 1.5942 - acc: 0.4354 - val_loss: 2.1138 - val_acc: 0.3872\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 39s 63ms/step - loss: 1.1019 - acc: 0.6189 - val_loss: 0.9791 - val_acc: 0.6618\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 39s 63ms/step - loss: 0.9189 - acc: 0.6887 - val_loss: 1.3828 - val_acc: 0.5751\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 40s 65ms/step - loss: 0.7868 - acc: 0.7347 - val_loss: 1.2530 - val_acc: 0.6168\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 39s 63ms/step - loss: 0.6843 - acc: 0.7691 - val_loss: 0.9573 - val_acc: 0.7079\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 40s 64ms/step - loss: 0.5943 - acc: 0.8023 - val_loss: 1.6850 - val_acc: 0.6463\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 39s 63ms/step - loss: 0.5133 - acc: 0.8270 - val_loss: 1.0864 - val_acc: 0.6834\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 40s 64ms/step - loss: 0.4446 - acc: 0.8507 - val_loss: 1.0051 - val_acc: 0.7375\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - 40s 64ms/step - loss: 0.3924 - acc: 0.8689 - val_loss: 1.2244 - val_acc: 0.7204\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - 40s 64ms/step - loss: 0.3472 - acc: 0.8840 - val_loss: 1.0542 - val_acc: 0.7429\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_tr, y_tr, batch_size=64, epochs=10, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train (again) and evaluate the model\n",
    "\n",
    "- To this end, you have found the \"best\" hyper-parameters. \n",
    "- Now, fix the hyper-parameters and train the network on the entire training set (all the 50K training samples)\n",
    "- Evaluate your model on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Train the model on the entire training set\n",
    "\n",
    "Why? Previously, you used 40K samples for training; you wasted 10K samples for the sake of hyper-parameter tuning. Now you already know the hyper-parameters, so why not using all the 50K samples for training?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <Compile your model again (using the same hyper-parameters)>\n",
    "# ...\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=learning_rate),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "782/782 [==============================] - 44s 56ms/step - loss: 0.4712 - acc: 0.8567\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 46s 59ms/step - loss: 0.3798 - acc: 0.8782\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 45s 57ms/step - loss: 0.3265 - acc: 0.8959\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 45s 58ms/step - loss: 0.2849 - acc: 0.9084\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 46s 58ms/step - loss: 0.2524 - acc: 0.9193\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 45s 58ms/step - loss: 0.2244 - acc: 0.9288\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 46s 59ms/step - loss: 0.2042 - acc: 0.9357\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 46s 59ms/step - loss: 0.1974 - acc: 0.9387\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 46s 58ms/step - loss: 0.1760 - acc: 0.9451\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 46s 59ms/step - loss: 0.1673 - acc: 0.9493\n"
     ]
    }
   ],
   "source": [
    "# <Train your model on the entire training set (50K samples)>\n",
    "# <Use (x_train, y_train_vec) instead of (x_tr, y_tr)>\n",
    "# <Do NOT use the validation_data option (because now you do not have validation data)>\n",
    "# ...\n",
    "\n",
    "history = model.fit(x_train, y_train_vec, batch_size=64, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Evaluate the model on the test set\n",
    "\n",
    "Do NOT used the test set until now. Make sure that your model parameters and hyper-parameters are independent of the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 4s 12ms/step - loss: 1.4582 - acc: 0.7497\n",
      "loss = 1.4582217931747437\n",
      "accuracy = 0.7497000098228455\n"
     ]
    }
   ],
   "source": [
    "loss_and_acc = model.evaluate(x_test, y_test_vec)\n",
    "print('loss = ' + str(loss_and_acc[0]))\n",
    "print('accuracy = ' + str(loss_and_acc[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Notes\n",
    "After several different iterations exploring different optimizations, my final model was able to achieve a high training accuracy and sub-par validation and testing accuracy. The final accuracy scores are:\n",
    "- **Training**: 0.9493\n",
    "- **Validation**: 0.7429\n",
    "- **Testing**: 0.7497\n",
    "\n",
    "These scores are indicative that the model is overfitting on the training data and not generalizing enough on the unseen data. This trend persisted through nearly all of my optimization loops. I used the following optimizations to attempt to combat the overfitting problem specifically:\n",
    "- Dropout in various stages of the model stack\n",
    "- Varying dropout rates between .1 and .5\n",
    "- L2 Normalization on Convolutional Layers\n",
    "\n",
    "Other optimization methods I tried in an attempt to raise the general accuracy include:\n",
    "- Additional Convolutional loops in the model stack\n",
    "- Varying convolutional filter sizes\n",
    "- Non-square convolutional filter sizes\n",
    "- Adding Batch Normalization\n",
    "- Adding dropout\n",
    "- Adjusting the learning rate\n",
    "- Adjusting the batch size\n",
    "\n",
    "My final model utilized all of the methods mentioned above (excluding the L2 regularization because I observed no improvements):\n",
    "- **Learning Rate**: 0.001\n",
    "- **Batch Size**: 64\n",
    "\n",
    "**Note**: I saved all graphs from the training loops and these can be provided upon request for validation that changes were made."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
